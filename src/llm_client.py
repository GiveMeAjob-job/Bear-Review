# src/llm_client.py - ğŸ”„ æ”¯æŒå¤šæ¨¡å‹
"""
LLMClient  â€”â€” ç»Ÿä¸€å°è£… DeepSeek / OpenAI èŠå¤©æ¨¡å‹
-------------------------------------------------
ä¾èµ–ç‰ˆæœ¬ï¼š
    pip install "openai>=1.17.0"
"""

from __future__ import annotations

from typing import Any, Dict
from openai import OpenAI          # âœ… æ–°ç‰ˆ SDK éƒ½ä»è¿™é‡Œ import
from .config import Config
from .utils import retry_on_failure, setup_logger

logger = setup_logger(__name__)


class LLMClient:
    """æ”¯æŒ DeepSeek ä¸ OpenAI çš„èŠå¤©è¡¥å…¨å°è£…"""

    def __init__(self, cfg: Config) -> None:
        self.cfg = cfg
        self.client: OpenAI        # å£°æ˜ç±»å‹
        self.model: str
        self._setup_client()

    # --------------------------------------------------------------------- #
    # åˆå§‹åŒ–
    # --------------------------------------------------------------------- #
    def _setup_client(self) -> None:
        """æ ¹æ® env é…ç½®å®ä¾‹åŒ– OpenAI / DeepSeek å®¢æˆ·ç«¯"""
        if self.cfg.llm_provider.lower() == "deepseek":
            if not self.cfg.deepseek_key:
                raise ValueError("DeepSeek API Key æœªè®¾ç½®")

            # âš ï¸ base_url **ä¸å¸¦** /v1
            self.client = OpenAI(
                api_key=self.cfg.deepseek_key,
                base_url="https://api.deepseek.com",
            )
            self.model = self.cfg.llm_model or "deepseek-reasoner"

        elif self.cfg.llm_provider.lower() == "openai":
            if not self.cfg.openai_key:
                raise ValueError("OpenAI API Key æœªè®¾ç½®")

            self.client = OpenAI(api_key=self.cfg.openai_key)
            self.model = self.cfg.llm_model or "gpt-3.5-turbo"

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ LLM_PROVIDER: {self.cfg.llm_provider}")

        logger.info(f"ğŸ”§ LLM åˆå§‹åŒ–å®Œæˆ â†’ provider={self.cfg.llm_provider}  model={self.model}")

    # --------------------------------------------------------------------- #
    # è°ƒç”¨
    # --------------------------------------------------------------------- #
    @retry_on_failure(max_retries=3)
    def ask_llm(
            self,
            prompt: str,
            max_tokens: int = 800,
            temperature: float = 0.7,
    ) -> str:
        """
        å‘ LLM å‘é€ promptï¼Œè¿”å›æ–‡æœ¬
        """
        system_msg = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸ªäººæ•ˆç‡åŠ©æ‰‹ï¼Œå–„äºæ€»ç»“ä»»åŠ¡å®Œæˆæƒ…å†µå¹¶ç»™å‡ºå®ç”¨å»ºè®®ã€‚"
            "è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒç®€æ´æœ‰æ¡ç†ã€‚"
        )
        messages: list[Dict[str, str]] = [
            {"role": "system", "content": system_msg},
            {"role": "user", "content": prompt},
        ]

        try:
            # âœ… åŠ¨æ€æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "model": self.model,
                "messages": messages,
                "max_tokens": max_tokens,
            }

            # åªæœ‰å½“æ¨¡å‹ä¸æ˜¯ deepseek-reasoner æ—¶ï¼Œæ‰æ·»åŠ  temperature å’Œ top_p
            if self.model != "deepseek-reasoner":
                params["temperature"] = temperature
                params["top_p"] = 0.9

            # ä½¿ç”¨ **params è§£åŒ…ä¼ é€’å‚æ•°
            resp = self.client.chat.completions.create(**params)

            content = resp.choices[0].message.content.strip()
            logger.info(f"LLM å“åº”å­—æ•°ï¼š{len(content)}")
            return content

        except Exception as e:
            logger.error(f"LLM è°ƒç”¨å¤±è´¥: {e}")
            return f"[LLM è°ƒç”¨å¤±è´¥] {e}"

