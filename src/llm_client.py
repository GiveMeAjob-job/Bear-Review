# src/llm_client.py

from __future__ import annotations
from typing import Dict
from openai import OpenAI, BadRequestError
from .config import Config
from .utils import retry_on_failure, setup_logger

logger = setup_logger(__name__)

class LLMClient:
    def __init__(self, cfg: Config) -> None:
        self.cfg = cfg
        self.client: OpenAI
        self.model: str
        self._setup_client()

    # ------------------------------------------------------------------
    # åˆå§‹åŒ–ï¼šæ ¹æ® provider åˆ›å»º Clientï¼Œå¹¶è®¾å®šé»˜è®¤æ¨¡å‹
    # ------------------------------------------------------------------
    def _setup_client(self) -> None:
        provider = self.cfg.llm_provider.lower()

        if provider == "deepseek":
            if not self.cfg.deepseek_key:
                raise ValueError("DeepSeek API Key æœªè®¾ç½®")
            self.client = OpenAI(
                api_key=self.cfg.deepseek_key,
                base_url="https://api.deepseek.com",
            )
            # é»˜è®¤ reasonerï¼Œå¯é€šè¿‡ cfg è¦†ç›–
            self.model = self.cfg.llm_model or "deepseek-reasoner"

        elif provider == "openai":
            if not self.cfg.openai_key:
                raise ValueError("OpenAI API Key æœªè®¾ç½®")
            self.client = OpenAI(api_key=self.cfg.openai_key)
            self.model = self.cfg.llm_model or "gpt-3.5-turbo"

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ LLM_PROVIDER: {self.cfg.llm_provider}")

        logger.info(f"ğŸ”§ LLM åˆå§‹åŒ–å®Œæˆ â†’ provider={self.cfg.llm_provider}  model={self.model}")

    # ------------------------------------------------------------------
    # ä¸»æ¥å£ï¼šå‘ LLM å‘é€ promptï¼Œæ‹¿å›å›ç­”
    # ------------------------------------------------------------------
    @retry_on_failure(max_retries=3)
    def ask_llm(
        self,
        prompt: str,
        max_tokens: int = 800,
        temperature: float = 0.7,
    ) -> str:
        system_msg = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸ªäººæ•ˆç‡åŠ©æ‰‹ï¼Œå–„äºæ€»ç»“ä»»åŠ¡å®Œæˆæƒ…å†µå¹¶ç»™å‡ºå®ç”¨å»ºè®®ã€‚"
            "è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒç®€æ´æœ‰æ¡ç†ã€‚"
        )
        messages: list[Dict[str, str]] = [
            {"role": "system", "content": system_msg},
            {"role": "user", "content": prompt},
        ]

        params = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
        }

        try:
            resp = self.client.chat.completions.create(**params)
            msg = resp.choices[0].message

            # â‘  å…ˆå–æ ‡å‡† content
            content = (msg.content or "").strip()

            # â‘¡ å¦‚ä¸ºç©ºï¼Œå›é€€ reasoning_contentï¼ˆreasoner ä¸“å±å­—æ®µï¼‰
            if not content and getattr(msg, "reasoning_content", None):
                content = msg.reasoning_content.strip()

            # â‘¢ ä¾æ—§ä¸ºç©ºï¼Œç»™å‡ºå ä½æ–‡æœ¬ï¼Œä¾¿äºåç»­æ’æŸ¥
            if not content:
                content = "[â—æ¨¡å‹è¿”å›ç©º content ä¸ reasoning_content]"

            logger.info(f"LLM è¿”å›å­—æ•°ï¼š{len(content)}")
            return content

        except BadRequestError as e:
            logger.error(f"LLM è°ƒç”¨å¤±è´¥ (BadRequest): {e}")
            return f"[LLM è°ƒç”¨å¤±è´¥] {e}"
        except Exception as e:
            logger.error(f"LLM è°ƒç”¨å¤±è´¥: {e}")
            return f"[LLM è°ƒç”¨å¤±è´¥] {e}"
